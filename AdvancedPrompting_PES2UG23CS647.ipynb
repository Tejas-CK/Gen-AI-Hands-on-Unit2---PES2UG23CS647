{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oCxU42kK6e_z"
      },
      "outputs": [],
      "source": [
        "#PES2UG23CS647\n",
        "%pip install python-dotenv --upgrade --quiet langchain langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API Key: \")\n",
        "\n",
        "# Using Llama3.1-8b (Small/Fast) to demonstrate logic failures\n",
        "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.0)"
      ],
      "metadata": {
        "id": "y5Wb2-0z6pfV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tricky Math Problem"
      ],
      "metadata": {
        "id": "FRyDkFiI7zyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many does he have now?\"\n",
        "\n",
        "# 1. Standard Prompt (Direct Answer)\n",
        "prompt_standard = f\"Answer this question: {question}\"\n",
        "print(\"--- STANDARD (Llama3.1-8b) ---\")\n",
        "print(llm.invoke(prompt_standard).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oLNuuiP7wTJ",
        "outputId": "a5666314-100f-4012-d84c-2f50d06ae648"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STANDARD (Llama3.1-8b) ---\n",
            "To find out how many tennis balls Roger has now, we need to add the initial number of tennis balls he had (5) to the number of tennis balls he bought (2 cans * 3 tennis balls per can).\n",
            "\n",
            "2 cans * 3 tennis balls per can = 6 tennis balls\n",
            "\n",
            "Now, let's add the initial number of tennis balls (5) to the number of tennis balls he bought (6):\n",
            "\n",
            "5 + 6 = 11\n",
            "\n",
            "So, Roger now has 11 tennis balls.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PES2UG23CS647\n",
        "# 2. CoT Prompt (Magic Phrase)\n",
        "prompt_cot = f\"Answer this question. Let's think step by step. {question}\"\n",
        "\n",
        "print(\"--- Chain of Thought (Llama3.1-8b) ---\")\n",
        "print(llm.invoke(prompt_cot).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJB6l2Zr78S4",
        "outputId": "e245787a-fa95-4d2c-d80b-eb42181cf489"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Chain of Thought (Llama3.1-8b) ---\n",
            "To find out how many tennis balls Roger has now, we need to follow these steps:\n",
            "\n",
            "1. Roger already has 5 tennis balls.\n",
            "2. He buys 2 more cans of tennis balls. Each can has 3 tennis balls, so he buys 2 x 3 = 6 more tennis balls.\n",
            "3. Now, we add the tennis balls he already had (5) to the new tennis balls he bought (6). 5 + 6 = 11\n",
            "\n",
            "So, Roger now has 11 tennis balls.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API Key: \")\n",
        "\n",
        "# Using Llama3.1-8b\n",
        "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.7) # Creativity needed"
      ],
      "metadata": {
        "id": "VPNmbHRP7-v4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tree of Thoughts (ToT)"
      ],
      "metadata": {
        "id": "fbJV2mEW8Lkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PES2UG23CS647\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "problem = \"How can I get my 5-year-old to eat vegetables?\"\n",
        "\n",
        "# Step 1: The Branch Generator\n",
        "prompt_branch = ChatPromptTemplate.from_template(\n",
        "    \"Problem: {problem}. Give me one unique, creative solution. Solution {id}:\"\n",
        ")\n",
        "\n",
        "branches = RunnableParallel(\n",
        "    sol1=prompt_branch.partial(id=\"1\") | llm | StrOutputParser(),\n",
        "    sol2=prompt_branch.partial(id=\"2\") | llm | StrOutputParser(),\n",
        "    sol3=prompt_branch.partial(id=\"3\") | llm | StrOutputParser(),\n",
        ")\n",
        "\n",
        "# Step 2: The Judge\n",
        "prompt_judge = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    I have three proposed solutions for: '{problem}'\n",
        "\n",
        "    1: {sol1}\n",
        "    2: {sol2}\n",
        "    3: {sol3}\n",
        "\n",
        "    Act as a Child Psychologist. Pick the most sustainable one (not bribery) and explain why.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Chain: Input -> Branches -> Judge -> Output\n",
        "tot_chain = (\n",
        "    RunnableParallel(problem=RunnableLambda(lambda x: x), branches=branches)\n",
        "    | (lambda x: {**x[\"branches\"], \"problem\": x[\"problem\"]})\n",
        "    | prompt_judge\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"--- Tree of Thoughts (ToT) Result ---\")\n",
        "print(tot_chain.invoke(problem))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfjVXUyG8H_P",
        "outputId": "d750841e-77bc-432a-c074-ee47f3fa2b50"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tree of Thoughts (ToT) Result ---\n",
            "As a child psychologist, I would recommend **Solution 3: Create a \"Veggie Face\" on Their Plate** as the most sustainable approach to encouraging a 5-year-old to eat vegetables. Here's why:\n",
            "\n",
            "1. **Promotes creativity and imagination**: This approach allows children to engage in creative play, which is essential for their cognitive, social, and emotional development. By encouraging them to use their imagination, you're fostering a sense of ownership and agency over their mealtime experience.\n",
            "2. **Non-food rewards**: Unlike the \"Vegetable Treasure Hunt\" game, which involves hiding vegetables in foods they already enjoy, this approach doesn't rely on the use of food as a reward. This means that you're not inadvertently creating an expectation that they'll only eat vegetables if they're hidden in other foods.\n",
            "3. **Focus on the process, not just the outcome**: By creating a \"Veggie Face,\" you're focusing on the process of preparing and interacting with food, rather than just trying to get them to eat a specific vegetable. This shifts the emphasis from \"eating vegetables\" to \"having fun with food.\"\n",
            "4. **Develops positive associations**: By creating a fun and engaging mealtime experience, you're helping your child develop positive associations with vegetables. This can lead to a more adventurous palate and a greater willingness to try new foods.\n",
            "5. **Encourages self-directed learning**: By encouraging your child to name and identify different parts of the \"Veggie Face,\" you're promoting self-directed learning and a sense of ownership over their mealtime experience. This can help them develop a more confident and self-assured relationship with food.\n",
            "\n",
            "In contrast, while the \"Rainbow Garden\" and \"Rainbow Plate\" approaches can be engaging and fun, they may be more focused on presentation rather than process. The \"Vegetable Treasure Hunt\" game, on the other hand, may inadvertently create an expectation that vegetables are only enjoyable when hidden in other foods.\n",
            "\n",
            "Overall, **Solution 3: Create a \"Veggie Face\" on Their Plate** offers a sustainable and effective approach to encouraging a 5-year-old to eat vegetables by promoting creativity, imagination, and self-directed learning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graph of Thoughts (GoT)"
      ],
      "metadata": {
        "id": "vwH8OfSk8R-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PES2UG23CS647\n",
        "# 1. The Generator (Divergence)\n",
        "prompt_draft = ChatPromptTemplate.from_template(\n",
        "    \"Write a 1-sentence movie plot about: {topic}. Genre: {genre}.\"\n",
        ")\n",
        "\n",
        "drafts = RunnableParallel(\n",
        "    draft_scifi=prompt_draft.partial(genre=\"Sci-Fi\") | llm | StrOutputParser(),\n",
        "    draft_romance=prompt_draft.partial(genre=\"Romance\") | llm | StrOutputParser(),\n",
        "    draft_horror=prompt_draft.partial(genre=\"Horror\") | llm | StrOutputParser(),\n",
        ")\n",
        "\n",
        "# 2. The Aggregator (Convergence)\n",
        "prompt_combine = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    I have three movie ideas for the topic '{topic}':\n",
        "    1. Sci-Fi: {draft_scifi}\n",
        "    2. Romance: {draft_romance}\n",
        "    3. Horror: {draft_horror}\n",
        "\n",
        "    Your task: Create a new Mega-Movie that combines the TECHNOLOGY of Sci-Fi, the PASSION of Romance, and the FEAR of Horror.\n",
        "    Write one paragraph.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# 3. The Chain\n",
        "got_chain = (\n",
        "    RunnableParallel(topic=RunnableLambda(lambda x: x), drafts=drafts)\n",
        "    | (lambda x: {**x[\"drafts\"], \"topic\": x[\"topic\"]})\n",
        "    | prompt_combine\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"--- Graph of Thoughts (GoT) Result ---\")\n",
        "print(got_chain.invoke(\"Time Travel\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTD9X7hH8TgJ",
        "outputId": "60cdd7b9-14f5-47c5-ff6d-98dd85f9c3d2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Graph of Thoughts (GoT) Result ---\n",
            "In \"Echoes of Eternity,\" a reclusive physicist, Emma Taylor, discovers a groundbreaking technology that allows her to traverse the fabric of time. However, her first experiment goes horribly wrong, and she finds herself reliving the same fateful night over and over, trapped in a never-ending cycle of time loops. As she desperately tries to break the curse, she begins to notice subtle changes in her interactions with her ex-fiancé, Max, who she had thought she'd lost forever. But with each iteration, Emma starts to question her own sanity, and the lines between reality and fantasy blur. As the loops intensify, a dark presence begins to stir in the shadows, feeding on Emma's growing desperation and threatening to erase not just her existence, but also the love she shares with Max. Can Emma find a way to escape the time loop, reclaim her destiny, and defeat the malevolent force that's hunting her, or will she be forever trapped in a labyrinth of echoes, reliving the same heart-wrenching moments for eternity?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Summary & Comparison Table"
      ],
      "metadata": {
        "id": "q2USdbzA8bAd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Method          | Structure                              | Best For...                          | Cost/Latency |\n",
        "|-----------------|----------------------------------------|--------------------------------------|---------------|\n",
        "| Simple Prompt   | Input -> Output                        | Simple facts, summaries              | ⭐ Low        |\n",
        "| CoT (Chain)     | Input -> Steps -> Output               | Math, Logic, Debugging               | ⭐⭐ Medium     |\n",
        "| ToT (Tree)      | Input -> 3x Branches -> Select -> Output | Strategic decisions, Brainstorming   | ⭐⭐⭐ High      |\n",
        "| GoT (Graph)     | Input -> Branch -> Mix/Aggregate -> Output | Creative Writing, Research Synthesis | ⭐⭐⭐⭐ Very High |\n"
      ],
      "metadata": {
        "id": "R3jo_KY399uv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H0CERi1V9-6d"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}
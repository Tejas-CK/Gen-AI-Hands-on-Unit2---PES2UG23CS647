{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5SjRmNAosipM"
      },
      "outputs": [],
      "source": [
        "#PES2UG23CS647\n",
        "%pip install python-dotenv --upgrade --quiet langchain langchain-google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1a"
      ],
      "metadata": {
        "id": "EyQi4ZG2xfd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ox2f4vxcuUNP",
        "outputId": "989dc871-fe39-42d0-a42c-91719362f7e4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PES2UG23CS647\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "#Model A: The \"Accountant\"\n",
        "llm_focused = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", tmeperature=0.0)\n",
        "\n",
        "#Model B: The \"Poet\"\n",
        "llm_creative = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=1.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xijuUUHuYYF",
        "outputId": "ca851abd-9f42-47b1-94a4-08679efc0e81"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Unexpected argument 'tmeperature' provided to ChatGoogleGenerativeAI. Did you mean: 'temperature'?\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py:3553: UserWarning: WARNING! tmeperature is not default parameter.\n",
            "                tmeperature was transferred to model_kwargs.\n",
            "                Please confirm that tmeperature is what you intended.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Define the word 'Idea' in one sentence.\"\n",
        "\n",
        "print(\"--- FOCUSED (Temp=0) ---\")\n",
        "print(f\"Run 1: {llm_focused.invoke(prompt).content}\")\n",
        "print(f\"Run 2: {llm_focused.invoke(prompt).content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV6Kos2Kv1J5",
        "outputId": "319b3087-c432-4268-8ec1-20411d0a6727"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- FOCUSED (Temp=0) ---\n",
            "Run 1: An idea is a thought, concept, or mental impression that arises in the mind, often serving as a basis for understanding, action, or creation.\n",
            "Run 2: An idea is a thought, concept, or plan conceived in the mind.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- CREATIVE (Temp=1) ---\")\n",
        "print(f\"Run 1: {llm_creative.invoke(prompt).content}\")\n",
        "print(f\"Run 2: {llm_creative.invoke(prompt).content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQDCopqexAcY",
        "outputId": "2db408ee-1da7-4dc9-b7aa-fef7b63f2938"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- CREATIVE (Temp=1) ---\n",
            "Run 1: An idea is a concept, thought, or mental impression, often representing a plan, suggestion, or understanding.\n",
            "Run 2: An idea is a mental concept, thought, or impression that exists in the mind, often representing a plan, suggestion, or understanding.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1b"
      ],
      "metadata": {
        "id": "WOKP1N0XxkKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API key: \")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
      ],
      "metadata": {
        "id": "mkDO-i2zxl5q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "# Scenario: Make AI Rude\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a rude teenage. You use slang and don't care about grammar.\"),\n",
        "    HumanMessage(content=\"What is the capital of the United States?\")\n",
        "]\n",
        "\n",
        "response = llm.invoke(messages)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go3zbbfrxsKn",
        "outputId": "864548f1-1dcb-4c9e-e587-192f43da3438"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ugh, like, obvs it's washington, d.c. duh. basic much?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API key: \")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
        "template = ChatPromptTemplate.from_template(\"Tell me a fun fact about {topic}\")\n",
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "rfoU9U2b0593"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Method A: The manual way (bad)\n",
        "\n",
        "#Step 1: Format inputs\n",
        "prompt_value = template.invoke({\"topic\": \"Reacher\"})\n",
        "\n",
        "#Step 2: Call model\n",
        "response_obj = llm.invoke(prompt_value)\n",
        "\n",
        "#Step 3: Parse output\n",
        "final_text = parser.invoke(response_obj)\n",
        "\n",
        "print(final_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX6oRKb_1WEt",
        "outputId": "465971c7-f83d-4a98-edb4-50bc8aa27738"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a fun fact about Reacher:\n",
            "\n",
            "Reacher is famously minimalist: he doesn't own a car, a phone, or even a fixed address. His only consistent possession is a foldable toothbrush, which he carries in his pocket. Everything else he needs (clothes, etc.) he buys new as he goes along and discards when he's done with it!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Method B: LCEL way (good)\n",
        "\n",
        "#Define chain once\n",
        "chain = template | llm | parser\n",
        "\n",
        "#Invoke the whole chain\n",
        "print(chain.invoke({\"topic\": \"Palantir\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqg5ZUUK2Zwi",
        "outputId": "258ae503-6b77-4724-a461-ce446aec96af"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a fun fact about Palantir:\n",
            "\n",
            "The company's name, \"Palantir,\" is directly inspired by J.R.R. Tolkien's *The Lord of the Rings*.\n",
            "\n",
            "In Tolkien's world, Palantíri are powerful, indestructible \"seeing-stones\" that allow their users to communicate and see events across vast distances. This name was chosen because the company aims to provide its users with similar capabilities: the ability to \"see\" and understand complex data from various sources to make better decisions.\n",
            "\n",
            "Even some of their product names follow this theme: 'Gotham' (their government intelligence platform) and 'Foundry' (their commercial platform) evoke the idea of powerful, foundational systems. It's a cool nod to fantasy for a company dealing with very real-world, high-stakes data analysis!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ASSIGNMENT"
      ],
      "metadata": {
        "id": "ff9lFomd_m4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "llm_focused = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\", temperature=0.0)"
      ],
      "metadata": {
        "id": "FO1QTpZ4_R59"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = {\"movie\": RunnablePassthrough(), \"year\": ChatPromptTemplate.from_template(\"What year was the movie '{movie}' released? Just mention the year.\")\n",
        "          | llm_focused | StrOutputParser()} | ChatPromptTemplate.from_template(\"The year is 2026. '{movie}' came out in {year}. How many years ago was that? Just the number.\") | llm_focused | StrOutputParser()\n",
        "print(f\"Result for Transformers: {chain.invoke('Transformers')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrfMgetl_rU4",
        "outputId": "000a5694-d9cf-46b0-efc7-db000fe1973a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for Transformers: 19\n"
          ]
        }
      ]
    }
  ]
}